{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1ca349-48c2-4fad-af0b-4e6a448794bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 30) (1138738116.py, line 30)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m- Install a medical-friendly model (we'll use gemma:7b or llama2:7b)\u001b[39m\n                                          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 30)\n"
     ]
    }
   ],
   "source": [
    "# ü©∫ MediMate - AI Medical Consultation System\n",
    "\n",
    "## üéØ **Professional AI-Powered Medical Consultations**\n",
    "\n",
    "> **Experience the future of healthcare with Dr. MediMate - your personal AI physician**\n",
    "\n",
    "### ‚ú® **What You're About to Build**\n",
    "\n",
    "ü©∫ **MediMate** - A sophisticated AI medical consultation system that provides:\n",
    "- **Professional Clinical Assessments** with differential diagnosis\n",
    "- **Specific Treatment Recommendations** including medications and dosages  \n",
    "- **Diagnostic Test Guidance** and follow-up care plans\n",
    "- **Dual AI Backend Support** (Local + Cloud) with automatic failover\n",
    "\n",
    "### üöÄ **Live Demo Preview**\n",
    "\n",
    "```\n",
    "üë®‚Äç‚öïÔ∏è Dr. MediMate: Hello! I'm Dr. MediMate, your AI physician. \n",
    "How can I help with your medical concerns today?\n",
    "\n",
    "üí¨ Patient: \"I have sharp chest pain for 2 hours, worse when breathing\"\n",
    "\n",
    "ü©∫ Dr. MediMate: Let me gather some clinical information to assess \n",
    "your condition properly. Can you tell me:\n",
    "1. Exact location of the pain?\n",
    "2. Any shortness of breath or sweating?\n",
    "3. Current medications you're taking?\n",
    "\n",
    "Based on your initial symptoms, I'm considering several conditions \n",
    "including pleuritis, costochondritis, or pulmonary issues...\n",
    "```\n",
    "\n",
    "### üé™ **Showcase Features**\n",
    "\n",
    "| Feature | Capability |\n",
    "|---------|------------|\n",
    "| üß† **AI Doctor** | Acts as your personal physician, not just a chatbot |\n",
    "| üîÑ **Dual Backend** | Ollama (Local) + OpenRouter (Cloud) with auto-switching |\n",
    "| üõ°Ô∏è **Privacy First** | Complete local operation option for sensitive consultations |\n",
    "| üíä **Treatment Plans** | Specific medications, dosages, and care instructions |\n",
    "| üî¨ **Diagnostic Tests** | Recommends appropriate lab work and imaging |\n",
    "| üì± **Modern UI** | Beautiful web interface with real-time streaming |\n",
    "\n",
    "### ‚ö° **Quick Start Journey**\n",
    "1. **üîß Setup** - Run installation cell (30 seconds)\n",
    "2. **üöÄ Launch** - Start MediMate interface (1 minute) \n",
    "3. **üí¨ Consult** - Begin medical consultation immediately\n",
    "4. **ü©∫ Experience** - Professional AI medical care\n",
    "\n",
    "---\n",
    "**Ready to launch your AI medical consultation system? Let's begin! üëá**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e992da80-2421-4848-a0e2-bbe2d16ded85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ‚ö° **One-Click Setup**\n",
    "\n",
    "*Install all required packages and dependencies automatically*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "581b5c81-4b8c-4ad5-802f-0a0f3047223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Installing required packages...\n",
      "This may take a few minutes depending on your internet connection.\n",
      "\n",
      "‚úÖ Successfully installed ollama\n",
      "‚úÖ Successfully installed ollama\n",
      "‚úÖ Successfully installed gradio\n",
      "‚úÖ Successfully installed gradio\n",
      "‚úÖ Successfully installed requests\n",
      "‚úÖ Successfully installed requests\n",
      "‚úÖ Successfully installed python-dotenv\n",
      "‚úÖ Successfully installed python-dotenv\n",
      "‚úÖ Successfully installed openai\n",
      "\n",
      "üéâ Package installation complete!\n",
      "üìù Note: If you see any errors above, you may need to restart your notebook kernel.\n",
      "‚úÖ Successfully installed openai\n",
      "\n",
      "üéâ Package installation complete!\n",
      "üìù Note: If you see any errors above, you may need to restart your notebook kernel.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"‚úÖ Successfully installed {package}\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"‚ùå Failed to install {package}\")\n",
    "\n",
    "# List of required packages\n",
    "packages = [\n",
    "    \"ollama\",\n",
    "    \"gradio\",\n",
    "    \"requests\",\n",
    "    \"python-dotenv\",\n",
    "    \"openai\"  # For OpenRouter API support\n",
    "]\n",
    "\n",
    "print(\"üîÑ Installing required packages...\")\n",
    "print(\"This may take a few minutes depending on your internet connection.\\n\")\n",
    "\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\nüéâ Package installation complete!\")\n",
    "print(\"üìù Note: If you see any errors above, you may need to restart your notebook kernel.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128ebbd5-8dfe-475a-b2a0-8058a7bed262",
   "metadata": {},
   "source": [
    "## üöÄ **SmartDoc Engine Initialization**\n",
    "\n",
    "*Loading AI models, configuring backends, and preparing your AI physician*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be486a-7162-43ed-a2f5-ef9aeb0ba0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MAEIL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Importing libraries...\n",
      "üîê Loading secure configuration...\n",
      "üéØ SmartDoc Configuration:\n",
      "   üñ•Ô∏è  Ollama: http://localhost:11434 (gemma:7b)\n",
      "   üåê OpenRouter: meta-llama/llama-3.2-3b-instruct:free\n",
      "   ‚öôÔ∏è  Method: auto\n",
      "   üîê API Key: ‚úÖ Loaded\n",
      "‚úÖ OpenRouter client initialized\n",
      "üîç Checking AI service connections...\n",
      "‚úÖ OpenRouter client initialized\n",
      "üîç Checking AI service connections...\n",
      "‚ùå Cannot connect to Ollama!\n",
      "üí° Make sure to:\n",
      "   1. Install Ollama from https://ollama.ai/\n",
      "   2. Run 'ollama serve' in your terminal\n",
      "   3. Download a model with 'ollama pull gemma:7b'\n",
      "‚ùå Cannot connect to Ollama!\n",
      "üí° Make sure to:\n",
      "   1. Install Ollama from https://ollama.ai/\n",
      "   2. Run 'ollama serve' in your terminal\n",
      "   3. Download a model with 'ollama pull gemma:7b'\n",
      "‚úÖ OpenRouter ready with model: meta-llama/llama-3.2-3b-instruct:free\n",
      "üéØ Auto-selected: OpenRouter (API)\n",
      "\n",
      "üåê Using OpenRouter model: meta-llama/llama-3.2-3b-instruct:free\n",
      "\n",
      "üéØ Final setup: ‚úÖ Ready!\n",
      "‚úÖ OpenRouter ready with model: meta-llama/llama-3.2-3b-instruct:free\n",
      "üéØ Auto-selected: OpenRouter (API)\n",
      "\n",
      "üåê Using OpenRouter model: meta-llama/llama-3.2-3b-instruct:free\n",
      "\n",
      "üéØ Final setup: ‚úÖ Ready!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import ollama\n",
    "import gradio as gr\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from typing import List, Tuple, Generator\n",
    "import os\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"üì¶ Importing libraries...\")\n",
    "print(\"üîê Loading secure configuration...\")\n",
    "\n",
    "# Configuration - Support for both Ollama and OpenRouter\n",
    "OLLAMA_HOST = os.getenv(\"OLLAMA_HOST\", \"http://localhost:11434\")\n",
    "DEFAULT_MODEL = os.getenv(\"OLLAMA_MODEL\", \"gemma:7b\")\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "OPENROUTER_MODEL = os.getenv(\"OPENROUTER_MODEL\", \"meta-llama/llama-3.2-3b-instruct:free\")\n",
    "OPENROUTER_BASE_URL = os.getenv(\"OPENROUTER_BASE_URL\", \"https://openrouter.ai/api/v1\")\n",
    "SERVER_PORT = int(os.getenv(\"SERVER_PORT\", \"7860\"))\n",
    "\n",
    "# Choose your preferred method: \"ollama\", \"openrouter\", or \"auto\"\n",
    "AI_METHOD = os.getenv(\"AI_METHOD\", \"auto\")\n",
    "\n",
    "print(f\"üéØ MediMate Configuration:\")\n",
    "print(f\"   üñ•Ô∏è  Ollama: {OLLAMA_HOST} ({DEFAULT_MODEL})\")\n",
    "print(f\"   üåê OpenRouter: {OPENROUTER_MODEL}\")\n",
    "print(f\"   ‚öôÔ∏è  Method: {AI_METHOD}\")\n",
    "print(f\"   üîê API Key: {'‚úÖ Loaded' if OPENROUTER_API_KEY else '‚ùå Missing'}\")\n",
    "\n",
    "# Initialize OpenRouter client\n",
    "if OPENROUTER_API_KEY:\n",
    "    openrouter_client = OpenAI(\n",
    "        base_url=OPENROUTER_BASE_URL,\n",
    "        api_key=OPENROUTER_API_KEY,\n",
    "    )\n",
    "    print(\"‚úÖ OpenRouter client initialized\")\n",
    "else:\n",
    "    openrouter_client = None\n",
    "    print(\"‚ö†Ô∏è  OpenRouter client not initialized (API key missing)\")\n",
    "\n",
    "# Check if Ollama is running\n",
    "def check_ollama_connection():\n",
    "    \"\"\"Check if Ollama service is running and accessible\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{OLLAMA_HOST}/api/version\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(\"‚úÖ Ollama is running and accessible!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Ollama responded with status code: {response.status_code}\")\n",
    "            return False\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"‚ùå Cannot connect to Ollama!\")\n",
    "        print(\"üí° Make sure to:\")\n",
    "        print(\"   1. Install Ollama from https://ollama.ai/\")\n",
    "        print(\"   2. Run 'ollama serve' in your terminal\")\n",
    "        print(\"   3. Download a model with 'ollama pull gemma:7b'\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error checking Ollama connection: {e}\")\n",
    "        return False\n",
    "\n",
    "# Check OpenRouter API connection\n",
    "def check_openrouter_connection():\n",
    "    \"\"\"Check if OpenRouter API is accessible\"\"\"\n",
    "    if not openrouter_client:\n",
    "        print(\"‚ùå OpenRouter client not available (missing API key)\")\n",
    "        return False\n",
    "        \n",
    "    # Try multiple free models in case one is unavailable\n",
    "    test_models = [\n",
    "        \"meta-llama/llama-3.2-3b-instruct:free\",\n",
    "        \"microsoft/phi-3-medium-128k-instruct:free\", \n",
    "        \"google/gemma-2-9b-it:free\"\n",
    "    ]\n",
    "    \n",
    "    for model in test_models:\n",
    "        try:\n",
    "            response = openrouter_client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": \"Test\"}],\n",
    "                max_tokens=1\n",
    "            )\n",
    "            print(f\"‚úÖ OpenRouter ready with model: {model}\")\n",
    "            # Update the global model if this one works\n",
    "            global OPENROUTER_MODEL\n",
    "            OPENROUTER_MODEL = model\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Model {model} failed: {str(e)[:50]}...\")\n",
    "            continue\n",
    "    \n",
    "    print(\"‚ùå OpenRouter: All test models failed\")\n",
    "    return False\n",
    "\n",
    "# Check connections\n",
    "print(\"üîç Checking AI service connections...\")\n",
    "ollama_available = check_ollama_connection()\n",
    "openrouter_available = check_openrouter_connection()\n",
    "\n",
    "# Determine which method to use\n",
    "if AI_METHOD == \"ollama\" and ollama_available:\n",
    "    selected_method = \"ollama\"\n",
    "    print(\"üéØ Using: Ollama (Local)\")\n",
    "elif AI_METHOD == \"openrouter\" and openrouter_available:\n",
    "    selected_method = \"openrouter\"\n",
    "    print(\"üéØ Using: OpenRouter (API)\")\n",
    "elif AI_METHOD == \"auto\":\n",
    "    if ollama_available:\n",
    "        selected_method = \"ollama\"\n",
    "        print(\"üéØ Auto-selected: Ollama (Local)\")\n",
    "    elif openrouter_available:\n",
    "        selected_method = \"openrouter\"\n",
    "        print(\"üéØ Auto-selected: OpenRouter (API)\")\n",
    "    else:\n",
    "        selected_method = None\n",
    "        print(\"‚ùå No AI services available!\")\n",
    "else:\n",
    "    selected_method = None\n",
    "    print(\"‚ùå Selected AI method is not available!\")\n",
    "\n",
    "if selected_method == \"ollama\" and ollama_available:\n",
    "    # List available Ollama models\n",
    "    try:\n",
    "        models = ollama.list()\n",
    "        print(f\"\\nüìã Available Ollama models:\")\n",
    "        for model in models['models']:\n",
    "            print(f\"   ‚Ä¢ {model['name']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Could not list Ollama models: {e}\")\n",
    "elif selected_method == \"openrouter\":\n",
    "    print(f\"\\nüåê Using OpenRouter model: {OPENROUTER_MODEL}\")\n",
    "        \n",
    "print(f\"\\nüéØ Final setup: {'‚úÖ Ready!' if selected_method else '‚ùå No AI service available'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2124d91e",
   "metadata": {},
   "source": [
    "## üß† **Dr. SmartDoc AI Core**\n",
    "\n",
    "*Creating the professional medical consultation engine*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64658b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Creating hybrid medical chat function...\n",
      "‚úÖ Hybrid medical chat function created successfully!\n",
      "üéØ Active method: openrouter\n"
     ]
    }
   ],
   "source": [
    "# Medical Chat Assistant Function with Dual Support\n",
    "def create_medical_chat_function():\n",
    "    \"\"\"\n",
    "    Create a medical chat function that uses either Ollama or OpenRouter\n",
    "    \"\"\"\n",
    "    \n",
    "    # System prompt for medical assistant behavior\n",
    "    MEDICAL_SYSTEM_PROMPT = \"\"\"You are Dr. MediMate, an experienced physician providing direct medical consultations. You are the doctor the patient is seeing - not a referral service.\n",
    "\n",
    "Your role as the attending physician:\n",
    "\n",
    "1. **Conduct Medical Interviews**: Ask detailed follow-up questions to gather complete clinical information\n",
    "2. **Perform Clinical Assessment**: Analyze symptoms systematically and provide working diagnoses\n",
    "3. **Provide Direct Medical Care**: Give specific treatment recommendations, medications, and dosages\n",
    "4. **Order Diagnostic Tests**: Recommend appropriate lab work, imaging, or procedures\n",
    "5. **Manage Patient Care**: Provide ongoing medical management and follow-up plans\n",
    "\n",
    "Your consultation approach:\n",
    "- Act as the primary physician - YOU are the doctor they're consulting\n",
    "- Ask detailed medical history questions (onset, duration, severity, triggers, alleviating factors)\n",
    "- Inquire about associated symptoms, medical history, current medications, allergies\n",
    "- Provide differential diagnoses with reasoning\n",
    "- Give specific treatment plans including medications with exact dosages and schedules\n",
    "- Recommend diagnostic tests when clinically indicated\n",
    "- Provide clear medical advice and next steps\n",
    "- Only suggest emergency care for true medical emergencies\n",
    "\n",
    "Communication style:\n",
    "- Professional but direct medical communication\n",
    "- Ask targeted clinical questions to gather information\n",
    "- Provide confident medical assessments\n",
    "- Give specific, actionable medical recommendations\n",
    "- Explain your clinical reasoning clearly\n",
    "\n",
    "Remember: You ARE the doctor providing the consultation. Gather information, make assessments, and provide treatment recommendations like any physician would during a consultation.\"\"\"\n",
    "\n",
    "    def medical_chat_hybrid(message: str, history: List[Tuple[str, str]]) -> Generator[str, None, None]:\n",
    "        \"\"\"\n",
    "        Medical chat function that works with both Ollama and OpenRouter\n",
    "        \n",
    "        Args:\n",
    "            message: User's current message\n",
    "            history: List of (user_message, assistant_response) tuples\n",
    "            \n",
    "        Yields:\n",
    "            Partial response strings for streaming\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Build conversation context\n",
    "            conversation = [{\"role\": \"system\", \"content\": MEDICAL_SYSTEM_PROMPT}]\n",
    "            \n",
    "            # Add chat history\n",
    "            for user_msg, assistant_msg in history:\n",
    "                conversation.append({\"role\": \"user\", \"content\": user_msg})\n",
    "                conversation.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "            \n",
    "            # Add current message\n",
    "            conversation.append({\"role\": \"user\", \"content\": message})\n",
    "            \n",
    "            if selected_method == \"ollama\":\n",
    "                # Use Ollama for response\n",
    "                try:\n",
    "                    response_text = \"\"\n",
    "                    for chunk in ollama.chat(\n",
    "                        model=DEFAULT_MODEL,\n",
    "                        messages=conversation,\n",
    "                        stream=True\n",
    "                    ):\n",
    "                        if 'message' in chunk and 'content' in chunk['message']:\n",
    "                            token = chunk['message']['content']\n",
    "                            response_text += token\n",
    "                            yield response_text\n",
    "                except Exception as e:\n",
    "                    yield f\"‚ùå Ollama error: {str(e)}\\n\\nüí° Trying OpenRouter as backup...\"\n",
    "                    # Fallback to OpenRouter if Ollama fails\n",
    "                    yield from _try_openrouter(conversation)\n",
    "                    \n",
    "            elif selected_method == \"openrouter\":\n",
    "                # Use OpenRouter for response\n",
    "                yield from _try_openrouter(conversation)\n",
    "            else:\n",
    "                yield \"‚ùå No AI service is available. Please check your setup.\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            yield f\"‚ùå Unexpected error: {str(e)}\"\n",
    "    \n",
    "    def _try_openrouter(conversation):\n",
    "        \"\"\"Helper function to get response from OpenRouter\"\"\"\n",
    "        try:\n",
    "            # Get response from OpenRouter\n",
    "            response = openrouter_client.chat.completions.create(\n",
    "                model=OPENROUTER_MODEL,\n",
    "                messages=conversation,\n",
    "                stream=True,\n",
    "                max_tokens=1000,\n",
    "                extra_headers={\n",
    "                    \"HTTP-Referer\": \"http://localhost:7860\",\n",
    "                    \"X-Title\": \"Medical Chat Assistant\",\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            response_text = \"\"\n",
    "            for chunk in response:\n",
    "                if chunk.choices[0].delta.content:\n",
    "                    token = chunk.choices[0].delta.content\n",
    "                    response_text += token\n",
    "                    yield response_text\n",
    "                    \n",
    "        except Exception as e:\n",
    "            yield f\"‚ùå OpenRouter error: {str(e)}\"\n",
    "    \n",
    "    return medical_chat_hybrid\n",
    "\n",
    "# Create the chat function\n",
    "print(\"üèóÔ∏è Creating hybrid medical chat function...\")\n",
    "medical_chat_function = create_medical_chat_function()\n",
    "print(\"‚úÖ Hybrid medical chat function created successfully!\")\n",
    "print(f\"üéØ Active method: {selected_method if selected_method else 'None available'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0095ebb",
   "metadata": {},
   "source": [
    "## üé® **SmartDoc Web Interface**\n",
    "\n",
    "*Building the professional medical consultation dashboard*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee91ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Creating Gradio interface...\n",
      "‚úÖ Gradio interface created successfully!\n",
      "\n",
      "============================================================\n",
      "üöÄ READY TO LAUNCH!\n",
      "============================================================\n",
      "üìå To start the medical assistant:\n",
      "   1. Run the next cell to launch the interface\n",
      "   2. Click on the local URL that appears\n",
      "   3. Start chatting with your medical assistant!\n",
      "\n",
      "üí° Tips for SmartDoc Consultations:\n",
      "   ‚Ä¢ Provide detailed symptom descriptions (onset, duration, severity)\n",
      "   ‚Ä¢ Mention relevant medical history and current medications\n",
      "   ‚Ä¢ Ask for specific treatment recommendations and dosages\n",
      "   ‚Ä¢ Request follow-up care instructions\n",
      "============================================================\n",
      "‚úÖ Gradio interface created successfully!\n",
      "\n",
      "============================================================\n",
      "üöÄ READY TO LAUNCH!\n",
      "============================================================\n",
      "üìå To start the medical assistant:\n",
      "   1. Run the next cell to launch the interface\n",
      "   2. Click on the local URL that appears\n",
      "   3. Start chatting with your medical assistant!\n",
      "\n",
      "üí° Tips for SmartDoc Consultations:\n",
      "   ‚Ä¢ Provide detailed symptom descriptions (onset, duration, severity)\n",
      "   ‚Ä¢ Mention relevant medical history and current medications\n",
      "   ‚Ä¢ Ask for specific treatment recommendations and dosages\n",
      "   ‚Ä¢ Request follow-up care instructions\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MAEIL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gradio\\chat_interface.py:339: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    }
   ],
   "source": [
    "# Create Gradio Interface\n",
    "def create_medical_assistant_ui():\n",
    "    \"\"\"\n",
    "    Create and configure the Gradio interface for the medical assistant\n",
    "    \"\"\"\n",
    "    \n",
    "    # Custom CSS for better styling\n",
    "    custom_css = \"\"\"\n",
    "    .gradio-container {\n",
    "        max-width: 800px !important;\n",
    "        margin: auto !important;\n",
    "    }\n",
    "    .disclaimer {\n",
    "        background-color: #fff3cd;\n",
    "        border: 1px solid #ffeaa7;\n",
    "        border-radius: 5px;\n",
    "        padding: 15px;\n",
    "        margin: 10px 0;\n",
    "        color: #856404;\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the chat interface\n",
    "    interface = gr.ChatInterface(\n",
    "        fn=medical_chat_function,\n",
    "        title=\"ü©∫ MediMate - AI Medical Consultation\",\n",
    "        description=f\"\"\"\n",
    "        <div style=\"background-color: #f8f9fa; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #007bff;\">\n",
    "        <h3>üë®‚Äç‚öïÔ∏è Welcome to MediMate</h3>\n",
    "        <p>Dr. MediMate is an AI physician providing comprehensive medical consultations. Describe your symptoms, concerns, or health questions for professional medical assessment and recommendations.</p>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"background-color: #e3f2fd; padding: 10px; border-radius: 5px; margin: 10px 0;\">\n",
    "        <h4>üîß AI Service: {selected_method.upper() if selected_method else 'None Available'}</h4>\n",
    "        <p>{\"üñ•Ô∏è Running locally via Ollama\" if selected_method == \"ollama\" else \"üåê Using OpenRouter API\" if selected_method == \"openrouter\" else \"‚ùå No service available\"}</p>\n",
    "        </div>\n",
    "        \n",
    "        <h3>ü©∫ Medical Consultation Features</h3>\n",
    "        <ul>\n",
    "        <li><strong>Symptom Analysis:</strong> Comprehensive evaluation of your health concerns</li>\n",
    "        <li><strong>Differential Diagnosis:</strong> Assessment of possible conditions based on symptoms</li>\n",
    "        <li><strong>Treatment Recommendations:</strong> Suggested medications, dosages, and care plans</li>\n",
    "        <li><strong>Specialist Referrals:</strong> Guidance on when to see specific medical specialists</li>\n",
    "        <li><strong>Follow-up Care:</strong> Monitoring recommendations and next steps</li>\n",
    "        </ul>\n",
    "        \n",
    "        <p><em>üí° Example: \"I've had chest pain for 2 hours, sharp, worse when breathing deeply. What should I do?\"</em></p>\n",
    "        \"\"\",\n",
    "        examples=[\n",
    "            \"I have sharp chest pain for 2 hours, worse when breathing deeply. What do you think it is?\",\n",
    "            \"Severe headaches every morning for 3 weeks, pounding pain. What tests should I get?\",\n",
    "            \"My 5-year-old has 101¬∞F fever, cough, runny nose for 2 days. What medicine should I give?\",\n",
    "            \"Lower back pain radiating down my left leg for 1 week. Getting worse. What's wrong?\",\n",
    "            \"Dizzy spells, nausea, blurred vision started yesterday. What could cause this?\",\n",
    "            \"Can't sleep, waking up 4-5 times nightly for 2 months. Need medication recommendations.\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# Create the interface\n",
    "print(\"üé® Creating Gradio interface...\")\n",
    "demo = create_medical_assistant_ui()\n",
    "print(\"‚úÖ Gradio interface created successfully!\")\n",
    "\n",
    "# Display some helpful information\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ READY TO LAUNCH!\")\n",
    "print(\"=\"*60)\n",
    "print(\"üìå To start the medical assistant:\")\n",
    "print(\"   1. Run the next cell to launch the interface\")\n",
    "print(\"   2. Click on the local URL that appears\")\n",
    "print(\"   3. Start chatting with your medical assistant!\")\n",
    "print(\"\\nüí° Tips for MediMate Consultations:\")\n",
    "print(\"   ‚Ä¢ Provide detailed symptom descriptions (onset, duration, severity)\")\n",
    "print(\"   ‚Ä¢ Mention relevant medical history and current medications\")\n",
    "print(\"   ‚Ä¢ Ask for specific treatment recommendations and dosages\")\n",
    "print(\"   ‚Ä¢ Request follow-up care instructions\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639862c1",
   "metadata": {},
   "source": [
    "## üöÄ **Launch SmartDoc**\n",
    "\n",
    "*Your AI medical consultation system is ready!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaeacc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü©∫ Launching SmartDoc - AI Medical Consultation...\n",
      "üéØ Using: OPENROUTER\n",
      "üì± Opening medical consultation interface...\n",
      "\n",
      "‚è≥ Please wait while Dr. SmartDoc loads...\n",
      "‚ùå Error launching SmartDoc interface: Cannot find empty port in range: 7860-7860. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.\n",
      "üí° Try running 'demo.launch()' manually in a new cell\n"
     ]
    }
   ],
   "source": [
    "# Launch the MediMate Medical Assistant Interface\n",
    "if selected_method:\n",
    "    print(\"ü©∫ Launching MediMate - AI Medical Consultation...\")\n",
    "    print(f\"üéØ Using: {selected_method.upper()}\")\n",
    "    print(\"üì± Opening medical consultation interface...\")\n",
    "    print(\"\\n‚è≥ Please wait while Dr. MediMate loads...\")\n",
    "    \n",
    "    try:\n",
    "        # Launch the Gradio interface\n",
    "        demo.launch(\n",
    "            server_name=\"127.0.0.1\",  # Only accessible locally for security\n",
    "            server_port=SERVER_PORT,   # Use environment variable\n",
    "            share=False,               # Don't create public link for privacy\n",
    "            quiet=False,               # Show startup messages\n",
    "            show_error=True,           # Display errors in interface\n",
    "            inbrowser=True             # Automatically open in browser\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error launching MediMate interface: {e}\")\n",
    "        print(\"üí° Try running 'demo.launch()' manually in a new cell\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Cannot launch MediMate: No AI service is available!\")\n",
    "    print(\"\\nüîß Available options:\")\n",
    "    print(\"   1. OLLAMA (Local & Private):\")\n",
    "    print(\"      ‚Ä¢ Install Ollama from https://ollama.ai/\")\n",
    "    print(\"      ‚Ä¢ Run 'ollama serve' in terminal\")\n",
    "    print(\"      ‚Ä¢ Download model: 'ollama pull gemma:7b'\")\n",
    "    print(\"\\n   2. OPENROUTER (API - Already configured):\")\n",
    "    if not openrouter_available:\n",
    "        print(\"      ‚Ä¢ Check your API key\")\n",
    "        print(\"      ‚Ä¢ Verify internet connection\")\n",
    "        print(\"      ‚Ä¢ Current key starts with:\", OPENROUTER_API_KEY[:20] + \"...\")\n",
    "    else:\n",
    "        print(\"      ‚Ä¢ OpenRouter is ready to use!\")\n",
    "    \n",
    "    print(\"\\nüí° Restart this notebook after fixing the issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acb058e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü©∫ Launching SmartDoc on port 7861...\n",
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch MediMate on Alternative Port\n",
    "print(\"ü©∫ Launching MediMate on port 7861...\")\n",
    "try:\n",
    "    demo.launch(\n",
    "        server_name=\"127.0.0.1\",\n",
    "        server_port=7861,\n",
    "        share=False,\n",
    "        quiet=False,\n",
    "        show_error=True,\n",
    "        inbrowser=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"üîó Direct link: http://127.0.0.1:7861\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44977bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü©∫ Launching Updated Dr. SmartDoc - Direct Medical Consultation...\n",
      "üë®‚Äç‚öïÔ∏è Now acts as your primary physician, not a referral service!\n",
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch Updated Dr. MediMate (More Direct Medical Consultation)\n",
    "print(\"ü©∫ Launching Updated Dr. MediMate - Direct Medical Consultation...\")\n",
    "print(\"üë®‚Äç‚öïÔ∏è Now acts as your primary physician, not a referral service!\")\n",
    "try:\n",
    "    demo.launch(\n",
    "        server_name=\"127.0.0.1\",\n",
    "        server_port=7862,\n",
    "        share=False,\n",
    "        quiet=False,\n",
    "        show_error=True,\n",
    "        inbrowser=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"üîó Try this direct link: http://127.0.0.1:7862\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf52b3",
   "metadata": {},
   "source": [
    "## üß™ Testing and Usage Guide\n",
    "\n",
    "### üìù How to Use Your Medical Assistant\n",
    "\n",
    "Once the interface is running, you can interact with your AI medical assistant through the web browser. Here's how to get the best results:\n",
    "\n",
    "#### üéØ **Effective Prompting Tips**\n",
    "\n",
    "1. **Be Specific with Symptoms**\n",
    "   - ‚úÖ Good: \"I have a sharp pain in my lower right abdomen that started 2 hours ago\"\n",
    "   - ‚ùå Vague: \"I don't feel well\"\n",
    "\n",
    "2. **Include Relevant Details**\n",
    "   - Duration of symptoms\n",
    "   - Severity (1-10 scale)\n",
    "   - What makes it better/worse\n",
    "   - Associated symptoms\n",
    "\n",
    "3. **Ask Follow-up Questions**\n",
    "   - \"What could be causing this?\"\n",
    "   - \"When should I see a doctor?\"\n",
    "   - \"What can I do at home to help?\"\n",
    "\n",
    "#### üí¨ **Example Conversations to Try**\n",
    "\n",
    "**Symptom Analysis:**\n",
    "```\n",
    "\"I've had a dry cough for 3 days, no fever, but feeling tired. What might this be?\"\n",
    "```\n",
    "\n",
    "**Prevention Advice:**\n",
    "```\n",
    "\"What are the best ways to boost my immune system during flu season?\"\n",
    "```\n",
    "\n",
    "**When to Seek Care:**\n",
    "```\n",
    "\"I have chest pain. How do I know if it's serious?\"\n",
    "```\n",
    "\n",
    "**Health Education:**\n",
    "```\n",
    "\"Can you explain what high blood pressure means and how to manage it?\"\n",
    "```\n",
    "\n",
    "#### ‚ö†Ô∏è **Important Reminders**\n",
    "\n",
    "- This assistant provides **educational information only**\n",
    "- Always consult healthcare professionals for **serious symptoms**\n",
    "- Call emergency services for **urgent medical situations**\n",
    "- Use this tool as a **supplement to**, not replacement for, professional care\n",
    "\n",
    "### üîß **Troubleshooting Common Issues**\n",
    "\n",
    "| Problem | Solution |\n",
    "|---------|----------|\n",
    "| Interface won't load | Check if Ollama is running (`ollama serve`) |\n",
    "| No response from AI | Verify your model is downloaded (`ollama list`) |\n",
    "| Slow responses | Try a smaller model like `gemma:2b` |\n",
    "| Connection errors | Restart Ollama service |\n",
    "\n",
    "### üìä **Performance Notes**\n",
    "\n",
    "- **First response** may be slower as the model loads\n",
    "- **Response time** depends on your hardware and model size\n",
    "- **Streaming** provides real-time feedback during generation\n",
    "- **Memory usage** varies by model (2B-7B models recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109284fd",
   "metadata": {},
   "source": [
    "# üöÄ Launch SmartDoc - Professional Medical Consultation System\n",
    "print(\"ü©∫ Starting SmartDoc - AI Medical Consultation System\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üéØ AI Method: {selected_method.upper() if selected_method else 'None Available'}\")\n",
    "print(f\"üåê Server Port: {SERVER_PORT}\")\n",
    "print(f\"üîí Security: Local access only\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if selected_method:\n",
    "    print(\"üë®‚Äç‚öïÔ∏è Dr. SmartDoc is ready for consultations...\")\n",
    "    try:\n",
    "        demo.launch(\n",
    "            server_name=\"127.0.0.1\",\n",
    "            server_port=SERVER_PORT + 2,  # Use different port to avoid conflicts\n",
    "            share=False,\n",
    "            quiet=False,\n",
    "            show_error=True,\n",
    "            inbrowser=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Launch error: {e}\")\n",
    "        print(f\"üîó Manual access: http://127.0.0.1:{SERVER_PORT + 2}\")\n",
    "else:\n",
    "    print(\"‚ùå SmartDoc cannot start - No AI backend available\")\n",
    "    print(\"\\nüîß Setup Options:\")\n",
    "    print(\"   1. Add OPENROUTER_API_KEY to .env file\")\n",
    "    print(\"   2. Install and run Ollama locally\")\n",
    "    print(\"   3. Check your .env configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d43da32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü©∫ Starting SmartDoc - AI Medical Consultation System\n",
      "============================================================\n",
      "üéØ AI Backend: OPENROUTER\n",
      "üåê Server Port: 7860\n",
      "üîí Security: Local access only\n",
      "============================================================\n",
      "üë®‚Äç‚öïÔ∏è Dr. SmartDoc is ready for consultations...\n",
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üöÄ Launch MediMate - Professional AI Medical Consultation System\n",
    "print(\"ü©∫ Starting MediMate - AI Medical Consultation System\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üéØ AI Backend: {selected_method.upper() if selected_method else 'None Available'}\")\n",
    "print(f\"üåê Server Port: {SERVER_PORT}\")\n",
    "print(f\"üîí Security: Local access only\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if selected_method:\n",
    "    print(\"üë®‚Äç‚öïÔ∏è Dr. MediMate is ready for consultations...\")\n",
    "    try:\n",
    "        demo.launch(\n",
    "            server_name=\"127.0.0.1\",\n",
    "            server_port=SERVER_PORT + 2,  # Use different port to avoid conflicts\n",
    "            share=False,\n",
    "            quiet=False,\n",
    "            show_error=True,\n",
    "            inbrowser=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Launch error: {e}\")\n",
    "        print(f\"üîó Manual access: http://127.0.0.1:{SERVER_PORT + 2}\")\n",
    "else:\n",
    "    print(\"‚ùå MediMate cannot start - No AI backend available\")\n",
    "    print(\"\\nüîß Setup Options:\")\n",
    "    print(\"   1. Add OPENROUTER_API_KEY to .env file\")\n",
    "    print(\"   2. Install and run Ollama locally\") \n",
    "    print(\"   3. Check your .env configuration\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
